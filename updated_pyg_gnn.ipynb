{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yjviwR2zCWb"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "RJGsLjWqzCWg"
      },
      "outputs": [],
      "source": [
        "%pip install graphdatascience python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou9RWeEizCWl"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLfww-ABzCWm"
      },
      "outputs": [],
      "source": [
        "!pip install neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "lnzpfIdazCWn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from graphdatascience import GraphDataScience\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtuFisr8zCWo"
      },
      "outputs": [],
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "# URI examples: \"neo4j://localhost\", \"neo4j+s://xxx.databases.neo4j.io\"\n",
        "URI = \"bolt://localhost:7687\"\n",
        "AUTH = (\"shivam\", \"graphAccess001\")\n",
        "\n",
        "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
        "    driver.verify_connectivity()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "jSBGKAOCzCWp"
      },
      "outputs": [],
      "source": [
        "load_dotenv('db-credentials.env', override=True)\n",
        "\n",
        "# Use Neo4j URI and credentials according to our setup\n",
        "gds = GraphDataScience(\n",
        "    os.getenv('bolt://localhost:7687'),\n",
        "    auth=(os.getenv('shivam'),\n",
        "          os.getenv('graphAccess001')),\n",
        "    aura_ds=eval(os.getenv('AURA_DS').title()))\n",
        "\n",
        "# Necessary if you enabled Arrow on the db - this is true for AuraDS\n",
        "gds.set_database(\"neo4j\")\n",
        "PROJ_NAME = 'proj'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "d19lxsDnzCWq",
        "outputId": "76f2945c-777b-49f9-b7b5-5f819e49ff41"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7847546d4b76>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'gds' is not defined"
          ]
        }
      ],
      "source": [
        "gds.version()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM5iisEuzCWq"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 7474"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq9svGgqzCWr"
      },
      "source": [
        "## Sample Neo4j Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HifMVCb3zCWr"
      },
      "outputs": [],
      "source": [
        "if gds.graph.exists(PROJ_NAME)['exists']:\n",
        "    gds.graph.get(PROJ_NAME).drop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "7901cbb0eade4e1387efcebb9667937b"
          ]
        },
        "id": "HgVov8_qzCWs",
        "outputId": "b094c6bb-80a6-43dd-e259-07a115905eac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7901cbb0eade4e1387efcebb9667937b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading:   0%|          | 0/100 [00:00<?, ?%/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 28.3 ms, sys: 8.72 ms, total: 37 ms\n",
            "Wall time: 2.12 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "g, _ = gds.graph.project(PROJ_NAME, ['Train', 'Valid', 'Test'], ['Employees'],\n",
        "                         nodeProperties =['YOE', 'Designation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJ-bEXmGzCWt"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of nodes in our graph: {g.node_count():,}\")\n",
        "print(f\"Number of relationships in our graph: {g.relationship_count():,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZQOtAbCzCWt"
      },
      "outputs": [],
      "source": [
        "SAMPLE_PROJ_NAME = PROJ_NAME + '_sample'\n",
        "if gds.graph.exists(SAMPLE_PROJ_NAME)['exists']:\n",
        "    gds.graph.get(SAMPLE_PROJ_NAME).drop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "26eadc8de3f94954bb88b8068148132f"
          ]
        },
        "id": "5jj2mjwSzCWu",
        "outputId": "98c25a92-f4a7-42d7-b25c-bdbc60098cd6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26eadc8de3f94954bb88b8068148132f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Random walk with restarts sampling:   0%|          | 0/100 [00:00<?, ?%/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 448 ms, sys: 34.4 ms, total: 483 ms\n",
            "Wall time: 1min\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "g_sample, _ = gds.alpha.graph.sample.rwr(SAMPLE_PROJ_NAME, g,\n",
        "                                         restartProbability=0.05, nodeLabelStratification=True,\n",
        "                                         concurrency=1, randomSeed=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj2w8v2YzCWv"
      },
      "source": [
        "## Export Sampled Graph to Pandas DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrecB7DRzCWw"
      },
      "outputs": [],
      "source": [
        "raw_topology_df = gds.beta.graph.relationships.stream(g_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnxktjD3zCWw"
      },
      "outputs": [],
      "source": [
        "sample_node_df = raw_topology_df.reset_index().rename(columns={'nodeId':'neo4jNodeId'}).rename(columns={'index':'nodeId'})\n",
        "sample_node_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJfChNiNzCWx"
      },
      "outputs": [],
      "source": [
        "sample_topology_df = (raw_topology_df\n",
        "    .merge(sample_node_df[['neo4jNodeId','nodeId']], how='left',\n",
        "           left_on='sourceNodeId', right_on='neo4jNodeId')\n",
        "    .drop(columns=['sourceNodeId', 'neo4jNodeId'])\n",
        "    .rename(columns={'nodeId':'sourceNodeId'})\n",
        "    .merge(sample_node_df[['neo4jNodeId','nodeId']], how='left',\n",
        "           left_on='targetNodeId', right_on='neo4jNodeId')\n",
        "    .drop(columns=['targetNodeId', 'neo4jNodeId'])\n",
        "    .rename(columns={'nodeId':'targetNodeId'})\n",
        ")\n",
        "sample_topology_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaLiKxgWzCWx"
      },
      "source": [
        "## Construct Inputs for Training\n",
        "Now that we re-assigned node ids, we can easily transform our `sample_topology_df` and `node_df` into the `edge_index`, features (`x`), and target (`y`) tensors for PyG. We will also use `node_df.year` for data splitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9lpwqwWzCWx"
      },
      "outputs": [],
      "source": [
        "# By using `by_rel_type` we get the topology in a format that can be used as input to several GNN frameworks:\n",
        "# {\"rel_type\": [[source_nodes], [target_nodes]]}\n",
        "sample_topology = sample_topology_df.by_rel_type()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN_cVVgYzCWy",
        "outputId": "6bc19eee-26cb-43ae-b40e-47ca548b1f14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[    0,     0,     0,  ..., 57576, 57576, 57576],\n",
              "        [48832, 50197, 50560,  ..., 36918, 36977, 26490]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edge_index = torch.tensor(sample_topology['Skills'], dtype=torch.long)\n",
        "edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfLmnHgdzCWy"
      },
      "outputs": [],
      "source": [
        "#node features\n",
        "x = torch.tensor(np.stack(sample_node_df['employees']), dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnXwdzZnzCWy"
      },
      "outputs": [],
      "source": [
        "#target class\n",
        "y = torch.tensor(np.stack(sample_node_df['Skills']), dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JRDuYIHzCWy"
      },
      "outputs": [],
      "source": [
        "# data objects and masks for data splitting\n",
        "data = Data(x=x, y=y, edge_index=edge_index)\n",
        "data.train_mask = torch.tensor(np.stack(3 < sample_node_df.yoe < 7))\n",
        "data.val_mask = torch.tensor(np.stack(sample_node_df.year < 3))\n",
        "data.test_mask = torch.tensor(np.stack(sample_node_df.year > 7))\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpoTUcPdzCWz"
      },
      "outputs": [],
      "source": [
        "num_classes = y.unique().shape[0]\n",
        "print(f'there are {num_classes} possible target classes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0OL3OXezCWz"
      },
      "source": [
        "## Define Convolutional Neural Network and Other Configurations for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjz_1xs3zCWz"
      },
      "outputs": [],
      "source": [
        "# Define the GCN architecture\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(data.num_node_features, 72)\n",
        "        self.conv2 = GCNConv(72, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        # We use log_softmax and nll_loss instead of softmax output and cross entropy loss\n",
        "        # for reasons for performance and numerical stability.\n",
        "        # They are mathematically equivalent\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcfbHTsezCW0",
        "outputId": "8865c031-227c-42d6-9785-38cd63d34793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Prepare training by setting up for the chosen device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Let's see what device was chosen\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKB0ZUESzCW0",
        "outputId": "269bd9d3-ca89-46a8-d829-4a44e27a19fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(128, 72)\n",
            "  (conv2): GCNConv(72, 40)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# In standard PyTorch fashion we instantiate our model, and transfer it to the memory of the chosen device\n",
        "model = GCN().to(device)\n",
        "\n",
        "# Let's inspect our model architecture\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CAZ4C-6zCW0"
      },
      "outputs": [],
      "source": [
        "# Pass our input data to the chosen device too\n",
        "data = data.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfz6ZWWXzCW0"
      },
      "outputs": [],
      "source": [
        "# Since hyperparameter tuning is out of scope for this small example, we initialize an\n",
        "# Adam optimizer with some fixed learning rate and weight decay\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz2q3XfrzCW1"
      },
      "source": [
        "## Train and Evaluate GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRmRdHThzCW1",
        "outputId": "545952c3-6a0d-468f-aa06-06662df65bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Train: 3.8124, Valid: 3.7650, Test: 3.7201\n",
            "Epoch: 001, Train: 3.3731, Valid: 3.2336, Test: 3.3666\n",
            "Epoch: 002, Train: 3.2592, Valid: 2.8746, Test: 3.0503\n",
            "Epoch: 003, Train: 3.3073, Valid: 2.7021, Test: 2.7979\n",
            "Epoch: 004, Train: 3.4405, Valid: 2.7065, Test: 2.6882\n",
            "Epoch: 005, Train: 3.3579, Valid: 2.6410, Test: 2.6505\n",
            "Epoch: 006, Train: 3.2403, Valid: 2.5980, Test: 2.6353\n",
            "Epoch: 007, Train: 3.1113, Valid: 2.5501, Test: 2.6210\n",
            "Epoch: 008, Train: 2.9964, Valid: 2.5046, Test: 2.6095\n",
            "Epoch: 009, Train: 2.9466, Valid: 2.4629, Test: 2.5795\n",
            "Epoch: 010, Train: 2.9036, Valid: 2.4082, Test: 2.5354\n",
            "Epoch: 011, Train: 2.8694, Valid: 2.3436, Test: 2.5014\n",
            "Epoch: 012, Train: 2.8564, Valid: 2.3194, Test: 2.4805\n",
            "Epoch: 013, Train: 2.8281, Valid: 2.2840, Test: 2.4312\n",
            "Epoch: 014, Train: 2.7816, Valid: 2.2448, Test: 2.4202\n",
            "Epoch: 015, Train: 2.7344, Valid: 2.2156, Test: 2.3927\n",
            "Epoch: 016, Train: 2.6814, Valid: 2.1843, Test: 2.3644\n",
            "Epoch: 017, Train: 2.6233, Valid: 2.1484, Test: 2.3403\n",
            "Epoch: 018, Train: 2.5788, Valid: 2.1209, Test: 2.3131\n",
            "Epoch: 019, Train: 2.5380, Valid: 2.0887, Test: 2.2892\n",
            "Epoch: 020, Train: 2.5052, Valid: 2.0615, Test: 2.2615\n",
            "Epoch: 021, Train: 2.4797, Valid: 2.0328, Test: 2.2173\n",
            "Epoch: 022, Train: 2.4561, Valid: 2.0083, Test: 2.2024\n",
            "Epoch: 023, Train: 2.4349, Valid: 1.9804, Test: 2.1753\n",
            "Epoch: 024, Train: 2.3983, Valid: 1.9549, Test: 2.1536\n",
            "Epoch: 025, Train: 2.3671, Valid: 1.9373, Test: 2.1480\n",
            "Epoch: 026, Train: 2.3225, Valid: 1.9084, Test: 2.1399\n",
            "Epoch: 027, Train: 2.2953, Valid: 1.8936, Test: 2.1253\n",
            "Epoch: 028, Train: 2.2717, Valid: 1.8685, Test: 2.0945\n",
            "Epoch: 029, Train: 2.2439, Valid: 1.8530, Test: 2.0793\n",
            "Epoch: 030, Train: 2.2159, Valid: 1.8304, Test: 2.0541\n",
            "Epoch: 031, Train: 2.1870, Valid: 1.8065, Test: 2.0378\n",
            "Epoch: 032, Train: 2.1577, Valid: 1.7899, Test: 2.0290\n",
            "Epoch: 033, Train: 2.1256, Valid: 1.7777, Test: 2.0174\n",
            "Epoch: 034, Train: 2.1022, Valid: 1.7541, Test: 2.0053\n",
            "Epoch: 035, Train: 2.0843, Valid: 1.7397, Test: 1.9889\n",
            "Epoch: 036, Train: 2.0659, Valid: 1.7279, Test: 1.9788\n",
            "Epoch: 037, Train: 2.0467, Valid: 1.7115, Test: 1.9643\n",
            "Epoch: 038, Train: 2.0241, Valid: 1.6970, Test: 1.9419\n",
            "Epoch: 039, Train: 2.0023, Valid: 1.6817, Test: 1.9352\n",
            "Epoch: 040, Train: 1.9870, Valid: 1.6677, Test: 1.9235\n",
            "Epoch: 041, Train: 1.9672, Valid: 1.6628, Test: 1.9261\n",
            "Epoch: 042, Train: 1.9533, Valid: 1.6483, Test: 1.9180\n",
            "Epoch: 043, Train: 1.9416, Valid: 1.6343, Test: 1.9052\n",
            "Epoch: 044, Train: 1.9185, Valid: 1.6269, Test: 1.8883\n",
            "Epoch: 045, Train: 1.8999, Valid: 1.6161, Test: 1.8859\n",
            "Epoch: 046, Train: 1.8918, Valid: 1.6079, Test: 1.8723\n",
            "Epoch: 047, Train: 1.8790, Valid: 1.5970, Test: 1.8642\n",
            "Epoch: 048, Train: 1.8737, Valid: 1.5897, Test: 1.8663\n",
            "Epoch: 049, Train: 1.8579, Valid: 1.5861, Test: 1.8550\n",
            "Epoch: 050, Train: 1.8456, Valid: 1.5640, Test: 1.8459\n",
            "Epoch: 051, Train: 1.8365, Valid: 1.5643, Test: 1.8608\n",
            "Epoch: 052, Train: 1.8236, Valid: 1.5491, Test: 1.8496\n",
            "Epoch: 053, Train: 1.8189, Valid: 1.5542, Test: 1.8392\n",
            "Epoch: 054, Train: 1.8089, Valid: 1.5501, Test: 1.8313\n",
            "Epoch: 055, Train: 1.8051, Valid: 1.5386, Test: 1.8113\n",
            "Epoch: 056, Train: 1.7989, Valid: 1.5300, Test: 1.8237\n",
            "Epoch: 057, Train: 1.7902, Valid: 1.5240, Test: 1.8250\n",
            "Epoch: 058, Train: 1.7836, Valid: 1.5173, Test: 1.8033\n",
            "Epoch: 059, Train: 1.7767, Valid: 1.5099, Test: 1.8002\n",
            "Epoch: 060, Train: 1.7739, Valid: 1.5104, Test: 1.8030\n",
            "Epoch: 061, Train: 1.7640, Valid: 1.5032, Test: 1.7918\n",
            "Epoch: 062, Train: 1.7490, Valid: 1.4884, Test: 1.7895\n",
            "Epoch: 063, Train: 1.7435, Valid: 1.4866, Test: 1.7906\n",
            "Epoch: 064, Train: 1.7415, Valid: 1.4856, Test: 1.7838\n",
            "Epoch: 065, Train: 1.7446, Valid: 1.4838, Test: 1.7804\n",
            "Epoch: 066, Train: 1.7315, Valid: 1.4711, Test: 1.7795\n",
            "Epoch: 067, Train: 1.7270, Valid: 1.4661, Test: 1.7669\n",
            "Epoch: 068, Train: 1.7238, Valid: 1.4699, Test: 1.7718\n",
            "Epoch: 069, Train: 1.7156, Valid: 1.4576, Test: 1.7667\n",
            "Epoch: 070, Train: 1.7038, Valid: 1.4610, Test: 1.7707\n",
            "Epoch: 071, Train: 1.7043, Valid: 1.4557, Test: 1.7681\n",
            "Epoch: 072, Train: 1.7025, Valid: 1.4505, Test: 1.7544\n",
            "Epoch: 073, Train: 1.7034, Valid: 1.4505, Test: 1.7529\n",
            "Epoch: 074, Train: 1.6974, Valid: 1.4433, Test: 1.7512\n",
            "Epoch: 075, Train: 1.6883, Valid: 1.4391, Test: 1.7533\n",
            "Epoch: 076, Train: 1.6891, Valid: 1.4386, Test: 1.7577\n",
            "Epoch: 077, Train: 1.6807, Valid: 1.4345, Test: 1.7370\n",
            "Epoch: 078, Train: 1.6774, Valid: 1.4277, Test: 1.7481\n",
            "Epoch: 079, Train: 1.6769, Valid: 1.4281, Test: 1.7471\n",
            "Epoch: 080, Train: 1.6689, Valid: 1.4190, Test: 1.7394\n",
            "Epoch: 081, Train: 1.6666, Valid: 1.4280, Test: 1.7465\n",
            "Epoch: 082, Train: 1.6555, Valid: 1.4136, Test: 1.7402\n",
            "Epoch: 083, Train: 1.6569, Valid: 1.4144, Test: 1.7345\n",
            "Epoch: 084, Train: 1.6668, Valid: 1.4046, Test: 1.7236\n",
            "Epoch: 085, Train: 1.6603, Valid: 1.4092, Test: 1.7401\n",
            "Epoch: 086, Train: 1.6517, Valid: 1.4037, Test: 1.7308\n",
            "Epoch: 087, Train: 1.6424, Valid: 1.3967, Test: 1.7468\n",
            "Epoch: 088, Train: 1.6483, Valid: 1.4024, Test: 1.7293\n",
            "Epoch: 089, Train: 1.6477, Valid: 1.3966, Test: 1.7269\n",
            "Epoch: 090, Train: 1.6502, Valid: 1.3914, Test: 1.7158\n",
            "Epoch: 091, Train: 1.6422, Valid: 1.3936, Test: 1.7245\n",
            "Epoch: 092, Train: 1.6348, Valid: 1.3897, Test: 1.7165\n",
            "Epoch: 093, Train: 1.6273, Valid: 1.3871, Test: 1.7208\n",
            "Epoch: 094, Train: 1.6334, Valid: 1.3863, Test: 1.7150\n",
            "Epoch: 095, Train: 1.6364, Valid: 1.3874, Test: 1.7109\n",
            "Epoch: 096, Train: 1.6379, Valid: 1.3776, Test: 1.7133\n",
            "Epoch: 097, Train: 1.6295, Valid: 1.3688, Test: 1.7094\n",
            "Epoch: 098, Train: 1.6271, Valid: 1.3777, Test: 1.7100\n",
            "Epoch: 099, Train: 1.6190, Valid: 1.3733, Test: 1.6941\n",
            "Epoch: 100, Train: 1.6293, Valid: 1.3804, Test: 1.7124\n",
            "Epoch: 101, Train: 1.6242, Valid: 1.3650, Test: 1.7008\n",
            "Epoch: 102, Train: 1.6279, Valid: 1.3640, Test: 1.7024\n",
            "Epoch: 103, Train: 1.6279, Valid: 1.3695, Test: 1.7112\n",
            "Epoch: 104, Train: 1.6187, Valid: 1.3678, Test: 1.7116\n",
            "Epoch: 105, Train: 1.6142, Valid: 1.3673, Test: 1.7134\n",
            "Epoch: 106, Train: 1.6148, Valid: 1.3719, Test: 1.7096\n",
            "Epoch: 107, Train: 1.6133, Valid: 1.3560, Test: 1.7023\n",
            "Epoch: 108, Train: 1.6175, Valid: 1.3629, Test: 1.6985\n",
            "Epoch: 109, Train: 1.6099, Valid: 1.3654, Test: 1.7083\n",
            "Epoch: 110, Train: 1.6027, Valid: 1.3600, Test: 1.7045\n",
            "Epoch: 111, Train: 1.6116, Valid: 1.3595, Test: 1.7086\n",
            "Epoch: 112, Train: 1.6158, Valid: 1.3511, Test: 1.7003\n",
            "Epoch: 113, Train: 1.6091, Valid: 1.3585, Test: 1.6863\n",
            "Epoch: 114, Train: 1.6025, Valid: 1.3478, Test: 1.7014\n",
            "Epoch: 115, Train: 1.6018, Valid: 1.3552, Test: 1.7039\n",
            "Epoch: 116, Train: 1.6126, Valid: 1.3498, Test: 1.6954\n",
            "Epoch: 117, Train: 1.6076, Valid: 1.3490, Test: 1.6920\n",
            "Epoch: 118, Train: 1.6080, Valid: 1.3509, Test: 1.6896\n",
            "Epoch: 119, Train: 1.5992, Valid: 1.3441, Test: 1.6896\n",
            "Epoch: 120, Train: 1.5967, Valid: 1.3433, Test: 1.6920\n",
            "Epoch: 121, Train: 1.5976, Valid: 1.3398, Test: 1.6978\n",
            "Epoch: 122, Train: 1.6032, Valid: 1.3462, Test: 1.6973\n",
            "Epoch: 123, Train: 1.6004, Valid: 1.3497, Test: 1.6823\n",
            "Epoch: 124, Train: 1.5925, Valid: 1.3466, Test: 1.6827\n",
            "Epoch: 125, Train: 1.5825, Valid: 1.3279, Test: 1.6826\n",
            "Epoch: 126, Train: 1.5992, Valid: 1.3422, Test: 1.6933\n",
            "Epoch: 127, Train: 1.5908, Valid: 1.3280, Test: 1.6837\n",
            "Epoch: 128, Train: 1.5964, Valid: 1.3406, Test: 1.6755\n",
            "Epoch: 129, Train: 1.5869, Valid: 1.3368, Test: 1.6822\n",
            "Epoch: 130, Train: 1.5871, Valid: 1.3266, Test: 1.6703\n",
            "Epoch: 131, Train: 1.5898, Valid: 1.3293, Test: 1.6736\n",
            "Epoch: 132, Train: 1.5946, Valid: 1.3302, Test: 1.6779\n",
            "Epoch: 133, Train: 1.5966, Valid: 1.3317, Test: 1.6811\n",
            "Epoch: 134, Train: 1.5831, Valid: 1.3179, Test: 1.6741\n",
            "Epoch: 135, Train: 1.5832, Valid: 1.3238, Test: 1.6818\n",
            "Epoch: 136, Train: 1.5883, Valid: 1.3235, Test: 1.6874\n",
            "Epoch: 137, Train: 1.5834, Valid: 1.3118, Test: 1.6758\n",
            "Epoch: 138, Train: 1.5800, Valid: 1.3179, Test: 1.6755\n",
            "Epoch: 139, Train: 1.5909, Valid: 1.3216, Test: 1.6777\n",
            "Epoch: 140, Train: 1.5816, Valid: 1.3260, Test: 1.6763\n",
            "Epoch: 141, Train: 1.5789, Valid: 1.3136, Test: 1.6721\n",
            "Epoch: 142, Train: 1.5793, Valid: 1.3136, Test: 1.6695\n",
            "Epoch: 143, Train: 1.5829, Valid: 1.3120, Test: 1.6684\n",
            "Epoch: 144, Train: 1.5787, Valid: 1.3111, Test: 1.6735\n",
            "Epoch: 145, Train: 1.5762, Valid: 1.3181, Test: 1.6723\n",
            "Epoch: 146, Train: 1.5795, Valid: 1.3068, Test: 1.6569\n",
            "Epoch: 147, Train: 1.5861, Valid: 1.3151, Test: 1.6754\n",
            "Epoch: 148, Train: 1.5741, Valid: 1.3118, Test: 1.6886\n",
            "Epoch: 149, Train: 1.5617, Valid: 1.3105, Test: 1.6756\n",
            "Epoch: 150, Train: 1.5658, Valid: 1.3082, Test: 1.6722\n",
            "Epoch: 151, Train: 1.5665, Valid: 1.3036, Test: 1.6658\n",
            "Epoch: 152, Train: 1.5680, Valid: 1.3179, Test: 1.6742\n",
            "Epoch: 153, Train: 1.5619, Valid: 1.2974, Test: 1.6610\n",
            "Epoch: 154, Train: 1.5718, Valid: 1.2932, Test: 1.6629\n",
            "Epoch: 155, Train: 1.5747, Valid: 1.3044, Test: 1.6628\n",
            "Epoch: 156, Train: 1.5612, Valid: 1.3074, Test: 1.6649\n",
            "Epoch: 157, Train: 1.5646, Valid: 1.3020, Test: 1.6698\n",
            "Epoch: 158, Train: 1.5619, Valid: 1.2982, Test: 1.6640\n",
            "Epoch: 159, Train: 1.5654, Valid: 1.2970, Test: 1.6659\n",
            "Epoch: 160, Train: 1.5712, Valid: 1.2984, Test: 1.6592\n",
            "Epoch: 161, Train: 1.5686, Valid: 1.2993, Test: 1.6613\n",
            "Epoch: 162, Train: 1.5638, Valid: 1.2938, Test: 1.6525\n",
            "Epoch: 163, Train: 1.5585, Valid: 1.2966, Test: 1.6659\n",
            "Epoch: 164, Train: 1.5535, Valid: 1.2913, Test: 1.6567\n",
            "Epoch: 165, Train: 1.5587, Valid: 1.3000, Test: 1.6605\n",
            "Epoch: 166, Train: 1.5662, Valid: 1.2937, Test: 1.6633\n",
            "Epoch: 167, Train: 1.5667, Valid: 1.2990, Test: 1.6644\n",
            "Epoch: 168, Train: 1.5598, Valid: 1.2892, Test: 1.6633\n",
            "Epoch: 169, Train: 1.5554, Valid: 1.2920, Test: 1.6598\n",
            "Epoch: 170, Train: 1.5592, Valid: 1.2908, Test: 1.6568\n",
            "Epoch: 171, Train: 1.5582, Valid: 1.2861, Test: 1.6458\n",
            "Epoch: 172, Train: 1.5525, Valid: 1.2866, Test: 1.6512\n",
            "Epoch: 173, Train: 1.5517, Valid: 1.2860, Test: 1.6590\n",
            "Epoch: 174, Train: 1.5614, Valid: 1.2919, Test: 1.6526\n",
            "Epoch: 175, Train: 1.5555, Valid: 1.2827, Test: 1.6478\n",
            "Epoch: 176, Train: 1.5528, Valid: 1.2729, Test: 1.6662\n",
            "Epoch: 177, Train: 1.5468, Valid: 1.2757, Test: 1.6507\n",
            "Epoch: 178, Train: 1.5549, Valid: 1.2879, Test: 1.6489\n",
            "Epoch: 179, Train: 1.5590, Valid: 1.2788, Test: 1.6416\n",
            "Epoch: 180, Train: 1.5537, Valid: 1.2915, Test: 1.6559\n",
            "Epoch: 181, Train: 1.5532, Valid: 1.2947, Test: 1.6562\n",
            "Epoch: 182, Train: 1.5524, Valid: 1.2863, Test: 1.6533\n",
            "Epoch: 183, Train: 1.5457, Valid: 1.2860, Test: 1.6575\n",
            "Epoch: 184, Train: 1.5448, Valid: 1.2777, Test: 1.6527\n",
            "Epoch: 185, Train: 1.5414, Valid: 1.2771, Test: 1.6572\n",
            "Epoch: 186, Train: 1.5436, Valid: 1.2750, Test: 1.6493\n",
            "Epoch: 187, Train: 1.5451, Valid: 1.2799, Test: 1.6609\n",
            "Epoch: 188, Train: 1.5392, Valid: 1.2741, Test: 1.6624\n",
            "Epoch: 189, Train: 1.5502, Valid: 1.2707, Test: 1.6573\n",
            "Epoch: 190, Train: 1.5607, Valid: 1.2769, Test: 1.6490\n",
            "Epoch: 191, Train: 1.5544, Valid: 1.2683, Test: 1.6425\n",
            "Epoch: 192, Train: 1.5374, Valid: 1.2660, Test: 1.6524\n",
            "Epoch: 193, Train: 1.5368, Valid: 1.2707, Test: 1.6530\n",
            "Epoch: 194, Train: 1.5493, Valid: 1.2719, Test: 1.6437\n",
            "Epoch: 195, Train: 1.5520, Valid: 1.2676, Test: 1.6480\n",
            "Epoch: 196, Train: 1.5394, Valid: 1.2727, Test: 1.6520\n",
            "Epoch: 197, Train: 1.5432, Valid: 1.2716, Test: 1.6426\n",
            "Epoch: 198, Train: 1.5435, Valid: 1.2693, Test: 1.6525\n",
            "Epoch: 199, Train: 1.5381, Valid: 1.2701, Test: 1.6495\n"
          ]
        }
      ],
      "source": [
        "# Train the GCN using the CORA sample represented by `data` using the standard PyTorch training loop\n",
        "model.train()\n",
        "for epoch in range(200):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    train_loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    valid_loss = F.nll_loss(out[data.val_mask], data.y[data.val_mask])\n",
        "    test_loss = F.nll_loss(out[data.test_mask], data.y[data.test_mask])\n",
        "    print(f'Epoch: {epoch:03d}, '\n",
        "      f'Train: {train_loss:.4f}, '\n",
        "      f'Valid: {valid_loss:.4f}, '\n",
        "      f'Test: {test_loss:.4f}')\n",
        "    valid_loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLBYPGrEzCW1",
        "outputId": "6f13d358-acfe-4290-a0a9-92f1a45179e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Accuracy: 0.5820\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the trained GCN model on our test set\n",
        "model.eval()\n",
        "pred = model(data).argmax(dim=1)\n",
        "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
        "acc = int(correct) / int(data.test_mask.sum())\n",
        "\n",
        "print(f\"Test Set Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi0E0v9fzCXC",
        "outputId": "6bb22f30-8779-4c92-d079-e96958a34df6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(x=[169343, 128], edge_index=[2, 1166243], y=[169343], train_mask=[169343], val_mask=[169343], test_mask=[169343])\n",
            "there are 40 possible target classes\n",
            "GCN(\n",
            "  (conv1): GCNConv(128, 72)\n",
            "  (conv2): GCNConv(72, 40)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "raw_topology_df = gds.beta.graph.relationships.stream(g)\n",
        "\n",
        "raw_node_df = gds.graph.nodeProperties.stream(\n",
        "    g,\n",
        "    ['designation', 'yoe'],\n",
        "    separate_property_columns=True,\n",
        ")\n",
        "\n",
        "node_df = raw_node_df.reset_index().rename(columns={'nodeId':'neo4jNodeId'}).rename(columns={'index':'nodeId'})\n",
        "\n",
        "topology_df = (raw_topology_df\n",
        "    .merge(node_df[['neo4jNodeId','nodeId']], how='left', left_on='sourceNodeId',\n",
        "           right_on='neo4jNodeId')\n",
        "    .drop(columns=['sourceNodeId', 'neo4jNodeId'])\n",
        "    .rename(columns={'nodeId':'sourceNodeId'})\n",
        "    .merge(node_df[['neo4jNodeId','nodeId']], how='left', left_on='targetNodeId',\n",
        "           right_on='neo4jNodeId')\n",
        "    .drop(columns=['targetNodeId', 'neo4jNodeId'])\n",
        "    .rename(columns={'nodeId':'targetNodeId'})\n",
        ")\n",
        "\n",
        "topology = topology_df.by_rel_type()\n",
        "\n",
        "edge_index = torch.tensor(topology['Skills'], dtype=torch.long)\n",
        "\n",
        "x = torch.tensor(np.stack(node_df['Employees']), dtype=torch.float)\n",
        "y = torch.tensor(np.stack(node_df['Designation']), dtype=torch.long)\n",
        "\n",
        "full_data = Data(x=x, y=y, edge_index=edge_index)\n",
        "full_data.train_mask = torch.tensor(np.stack(3 < sample_node_df.yoe < 7))\n",
        "full_data.val_mask = torch.tensor(np.stack(sample_node_df.year < 3))\n",
        "full_data.test_mask = torch.tensor(np.stack(sample_node_df.year > 7))\n",
        "\n",
        "num_classes = y.unique().shape[0]\n",
        "\n",
        "full_model = GCN().to(device)\n",
        "print(full_model)\n",
        "\n",
        "full_data = full_data.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(full_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "full_model.train()\n",
        "for epoch in range(200):\n",
        "    optimizer.zero_grad()\n",
        "    out = full_model(full_data)\n",
        "    train_loss = F.nll_loss(out[full_data.train_mask], full_data.y[full_data.train_mask])\n",
        "    valid_loss = F.nll_loss(out[full_data.val_mask], full_data.y[full_data.val_mask])\n",
        "    test_loss = F.nll_loss(out[full_data.test_mask], full_data.y[full_data.test_mask])\n",
        "    valid_loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo9wgujRzCXC",
        "outputId": "a032239e-0860-4eb1-b87f-5d84c42f591f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set accuracy for full dataset: 0.5583\n",
            "This is a difference of -2.37 percentage points from the sampled dataset\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the full data trained GCN model on our test set\n",
        "full_model.eval()\n",
        "full_pred = full_model(full_data).argmax(dim=1)\n",
        "full_correct = (full_pred[full_data.test_mask] == full_data.y[full_data.test_mask]).sum()\n",
        "full_acc = int(full_correct) / int(full_data.test_mask.sum())\n",
        "\n",
        "print(f'Test set accuracy for full dataset: {full_acc:.4f}')\n",
        "print(f'This is a difference of {100*(full_acc-acc):.2f} percentage points from the sampled dataset')"
      ]
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "pytorch-gpu.1-13.m103",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}